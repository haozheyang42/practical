{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "val_df = pd.read_csv('data/val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for cleaning text\n",
    "def clean_html(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    # Remove HTML tags\n",
    "    clean = re.sub(r'<.*?>', '', str(text))\n",
    "    # Remove extra whitespaces\n",
    "    clean = re.sub(r'\\s+', ' ', clean).strip()\n",
    "    # Replace HTML entities\n",
    "    clean = re.sub(r'&amp;', '&', clean)\n",
    "    clean = re.sub(r'&lt;', '<', clean)\n",
    "    clean = re.sub(r'&gt;', '>', clean)\n",
    "    clean = re.sub(r'&quot;|&#34;', '\"', clean)\n",
    "    clean = re.sub(r'&apos;|&#39;', \"'\", clean)\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    snip   channel  \\\n",
      "0      first of all, it feels like covid again but in...  FOXNEWSW   \n",
      "1      to be a software drivenrganization where softw...     CSPAN   \n",
      "2      you discuss the <b>power</b> <b>of</b> <em>ai<...    CSPAN2   \n",
      "3      <em>ai</em> <b>bots</b> <b>like</b> chatgpt an...   BBCNEWS   \n",
      "4      . >> i could sleep <b>ten</b> <b>hours</b> <em...  FOXNEWSW   \n",
      "...                                                  ...       ...   \n",
      "19868  cardiovascular science, but they're also pione...  FOXNEWSW   \n",
      "19869  <b>i</b> <b>of</b> <em>ai</em> <b>in</b> <b>di...   BBCNEWS   \n",
      "19870  weighing down on the major averages, both tech...      KTVU   \n",
      "19871  i also <b>think</b> <b>crypto</b> <em>ai</em> ...    CSPAN2   \n",
      "19872  as we have worked to monitor the adoption iden...    CSPAN2   \n",
      "\n",
      "                                            cleaned_text  \n",
      "0      first of all, it feels like covid again but in...  \n",
      "1      to be a software drivenrganization where softw...  \n",
      "2      you discuss the power of ai to revolutionize t...  \n",
      "3      ai bots like chatgpt and google's bard gained ...  \n",
      "4      . >> i could sleep ten hours ai night if i was...  \n",
      "...                                                  ...  \n",
      "19868  cardiovascular science, but they're also pione...  \n",
      "19869  i of ai in different fields. have of ai in dif...  \n",
      "19870  weighing down on the major averages, both tech...  \n",
      "19871  i also think crypto ai that legislation be fro...  \n",
      "19872  as we have worked to monitor the adoption iden...  \n",
      "\n",
      "[19873 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "train_df['cleaned_text'] = train_df['snip'].apply(clean_html)\n",
    "val_df['cleaned_text'] = val_df['snip'].apply(clean_html)\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classes: ['1TV' 'ALJAZ' 'BBCNEWS' 'BELARUSTV' 'BLOOMBERG' 'CNBC' 'CNNW' 'COM'\n",
      " 'CSPAN' 'CSPAN2' 'CSPAN3' 'DW' 'FBC' 'FOXNEWSW' 'GBN' 'KDTV' 'KGO' 'KNTV'\n",
      " 'KPIX' 'KQED' 'KRON' 'KSTS' 'KTVU' 'LINKTV' 'MSNBCW' 'NTV' 'PRESSTV' 'RT'\n",
      " 'RUSSIA1' 'RUSSIA24' 'SFGTV']\n",
      "Num training classes: 31\n",
      "\n",
      "Validation classes: ['BLOOMBERG' 'KPIX' 'CNNW' 'CSPAN' 'BBCNEWS' 'FOXNEWSW' 'KTVU' 'KRON'\n",
      " 'KNTV' 'FBC' 'CNBC' 'KDTV' 'CSPAN2' 'KGO' 'DW' 'CSPAN3' 'GBN' 'ALJAZ'\n",
      " 'MSNBCW' 'RT' 'KSTS' 'SFGTV' 'KQED']\n",
      "Num validation classes: 23\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "train_df['channel_encoded'] = label_encoder.fit_transform(train_df['channel'])\n",
    "val_df['channel_encoded'] = label_encoder.transform(val_df['channel'])\n",
    "\n",
    "X_train = train_df['cleaned_text']\n",
    "y_train = train_df['channel_encoded']\n",
    "X_val = val_df['cleaned_text']\n",
    "y_val = val_df['channel_encoded']\n",
    "\n",
    "class_names = label_encoder.classes_\n",
    "print(f\"Training classes: {class_names}\")\n",
    "print(f\"Num training classes: {len(class_names)}\")\n",
    "\n",
    "val_class_names = val_df['channel'].unique()\n",
    "print(f\"\\nValidation classes: {val_class_names}\")\n",
    "print(f\"Num validation classes: {len(val_class_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training and Evaluating with TF-IDF Vectorizer ---\n",
      "Fitting TF-IDF Vectorizer...\n",
      "Transforming validation data with TF-IDF Vectorizer...\n",
      "Feature shape (Train): (19873, 66333)\n",
      "Training Logistic Regression model...\n",
      "Model training complete.\n",
      "\n",
      "Evaluating model...\n",
      "\n",
      "Overall Accuracy (TF-IDF Vectorizer):\n",
      "  Training Set: 0.8479\n",
      "  Validation Set: 0.5153\n",
      "\n",
      "Classification Report - Training Set (TF-IDF Vectorizer):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1TV       0.95      0.51      0.67       158\n",
      "       ALJAZ       1.00      0.89      0.94       230\n",
      "     BBCNEWS       0.70      0.96      0.81      1576\n",
      "   BELARUSTV       0.97      0.51      0.67       109\n",
      "   BLOOMBERG       0.91      0.95      0.93      1441\n",
      "        CNBC       0.87      0.87      0.87      1319\n",
      "        CNNW       0.82      0.96      0.88      2725\n",
      "         COM       1.00      0.17      0.30        40\n",
      "       CSPAN       0.73      0.83      0.78       913\n",
      "      CSPAN2       0.71      0.69      0.70       904\n",
      "      CSPAN3       0.73      0.67      0.70       664\n",
      "          DW       1.00      0.85      0.92       253\n",
      "         FBC       0.90      0.91      0.90      1608\n",
      "    FOXNEWSW       0.86      0.84      0.85      1106\n",
      "         GBN       0.91      0.91      0.91       717\n",
      "        KDTV       0.93      0.99      0.96       176\n",
      "         KGO       0.96      0.73      0.83       763\n",
      "        KNTV       0.91      0.83      0.87       842\n",
      "        KPIX       0.97      0.58      0.73       400\n",
      "        KQED       1.00      0.15      0.26       113\n",
      "        KRON       0.94      0.89      0.91       760\n",
      "        KSTS       1.00      0.88      0.94       142\n",
      "        KTVU       0.90      0.86      0.88       766\n",
      "      LINKTV       1.00      0.30      0.46        43\n",
      "      MSNBCW       0.87      0.80      0.83      1141\n",
      "         NTV       0.92      0.80      0.86       209\n",
      "     PRESSTV       0.97      0.87      0.92       115\n",
      "          RT       1.00      0.38      0.55        50\n",
      "     RUSSIA1       1.00      0.18      0.30       108\n",
      "    RUSSIA24       1.00      0.45      0.62       122\n",
      "       SFGTV       0.98      0.90      0.94       360\n",
      "\n",
      "    accuracy                           0.85     19873\n",
      "   macro avg       0.92      0.71      0.76     19873\n",
      "weighted avg       0.86      0.85      0.84     19873\n",
      "\n",
      "\n",
      "Classification Report - Validation Set (TF-IDF Vectorizer):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ALJAZ       1.00      0.24      0.39        29\n",
      "     BBCNEWS       0.48      0.76      0.58       271\n",
      "   BLOOMBERG       0.58      0.84      0.69       170\n",
      "        CNBC       0.67      0.69      0.68       256\n",
      "        CNNW       0.35      0.76      0.47       219\n",
      "       CSPAN       0.43      0.49      0.46       204\n",
      "      CSPAN2       0.29      0.36      0.32       165\n",
      "      CSPAN3       0.29      0.03      0.06       177\n",
      "          DW       0.50      0.02      0.04        46\n",
      "         FBC       0.67      0.65      0.66       214\n",
      "    FOXNEWSW       0.65      0.50      0.57       250\n",
      "         GBN       0.20      0.86      0.32        14\n",
      "        KDTV       0.71      0.78      0.75        32\n",
      "         KGO       0.65      0.28      0.39       141\n",
      "        KNTV       0.55      0.32      0.41       185\n",
      "        KPIX       0.71      0.20      0.32        59\n",
      "        KQED       1.00      0.06      0.11        18\n",
      "        KRON       0.63      0.50      0.56       151\n",
      "        KSTS       0.74      0.77      0.76        22\n",
      "        KTVU       0.49      0.50      0.49       115\n",
      "      MSNBCW       0.67      0.58      0.62       223\n",
      "     PRESSTV       0.00      0.00      0.00         0\n",
      "          RT       0.00      0.00      0.00        41\n",
      "       SFGTV       0.89      0.22      0.35        37\n",
      "\n",
      "    accuracy                           0.52      3039\n",
      "   macro avg       0.55      0.43      0.42      3039\n",
      "weighted avg       0.54      0.52      0.49      3039\n",
      "\n",
      "\n",
      "--- Training and Evaluating with Count Vectorizer ---\n",
      "Fitting Count Vectorizer...\n",
      "Transforming validation data with Count Vectorizer...\n",
      "Feature shape (Train): (19873, 66333)\n",
      "Training Logistic Regression model...\n",
      "Model training complete.\n",
      "\n",
      "Evaluating model...\n",
      "\n",
      "Overall Accuracy (Count Vectorizer):\n",
      "  Training Set: 0.9850\n",
      "  Validation Set: 0.5186\n",
      "\n",
      "Classification Report - Training Set (Count Vectorizer):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1TV       1.00      1.00      1.00       158\n",
      "       ALJAZ       1.00      1.00      1.00       230\n",
      "     BBCNEWS       0.99      1.00      1.00      1576\n",
      "   BELARUSTV       1.00      1.00      1.00       109\n",
      "   BLOOMBERG       1.00      1.00      1.00      1441\n",
      "        CNBC       1.00      1.00      1.00      1319\n",
      "        CNNW       1.00      1.00      1.00      2725\n",
      "         COM       1.00      1.00      1.00        40\n",
      "       CSPAN       0.95      0.91      0.93       913\n",
      "      CSPAN2       0.91      0.86      0.88       904\n",
      "      CSPAN3       0.80      0.89      0.84       664\n",
      "          DW       1.00      1.00      1.00       253\n",
      "         FBC       1.00      1.00      1.00      1608\n",
      "    FOXNEWSW       1.00      1.00      1.00      1106\n",
      "         GBN       1.00      1.00      1.00       717\n",
      "        KDTV       1.00      1.00      1.00       176\n",
      "         KGO       1.00      1.00      1.00       763\n",
      "        KNTV       1.00      1.00      1.00       842\n",
      "        KPIX       1.00      1.00      1.00       400\n",
      "        KQED       1.00      1.00      1.00       113\n",
      "        KRON       1.00      1.00      1.00       760\n",
      "        KSTS       1.00      1.00      1.00       142\n",
      "        KTVU       1.00      1.00      1.00       766\n",
      "      LINKTV       1.00      1.00      1.00        43\n",
      "      MSNBCW       1.00      1.00      1.00      1141\n",
      "         NTV       1.00      1.00      1.00       209\n",
      "     PRESSTV       1.00      1.00      1.00       115\n",
      "          RT       1.00      1.00      1.00        50\n",
      "     RUSSIA1       1.00      0.99      1.00       108\n",
      "    RUSSIA24       1.00      1.00      1.00       122\n",
      "       SFGTV       1.00      1.00      1.00       360\n",
      "\n",
      "    accuracy                           0.99     19873\n",
      "   macro avg       0.99      0.99      0.99     19873\n",
      "weighted avg       0.99      0.99      0.99     19873\n",
      "\n",
      "\n",
      "Classification Report - Validation Set (Count Vectorizer):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1TV       0.00      0.00      0.00         0\n",
      "       ALJAZ       0.77      0.34      0.48        29\n",
      "     BBCNEWS       0.63      0.64      0.64       271\n",
      "   BLOOMBERG       0.64      0.82      0.72       170\n",
      "        CNBC       0.58      0.71      0.64       256\n",
      "        CNNW       0.42      0.62      0.50       219\n",
      "       CSPAN       0.43      0.47      0.44       204\n",
      "      CSPAN2       0.25      0.35      0.29       165\n",
      "      CSPAN3       0.34      0.10      0.16       177\n",
      "          DW       0.70      0.30      0.42        46\n",
      "         FBC       0.65      0.72      0.68       214\n",
      "    FOXNEWSW       0.56      0.48      0.52       250\n",
      "         GBN       0.20      0.64      0.31        14\n",
      "        KDTV       0.96      0.72      0.82        32\n",
      "         KGO       0.47      0.38      0.42       141\n",
      "        KNTV       0.41      0.39      0.40       185\n",
      "        KPIX       0.50      0.32      0.39        59\n",
      "        KQED       1.00      0.06      0.11        18\n",
      "        KRON       0.65      0.50      0.56       151\n",
      "        KSTS       0.69      0.91      0.78        22\n",
      "        KTVU       0.43      0.50      0.46       115\n",
      "      MSNBCW       0.61      0.61      0.61       223\n",
      "     PRESSTV       0.00      0.00      0.00         0\n",
      "          RT       0.00      0.00      0.00        41\n",
      "     RUSSIA1       0.00      0.00      0.00         0\n",
      "    RUSSIA24       0.00      0.00      0.00         0\n",
      "       SFGTV       0.85      0.30      0.44        37\n",
      "\n",
      "    accuracy                           0.52      3039\n",
      "   macro avg       0.47      0.40      0.40      3039\n",
      "weighted avg       0.52      0.52      0.51      3039\n",
      "\n",
      "\n",
      "--- Part A Complete ---\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate(vectorizer, vectorizer_name, X_train, y_train, X_val, y_val, class_names):\n",
    "    \"\"\"\n",
    "    Trains a Logistic Regression model using the specified vectorizer\n",
    "    and evaluates its performance.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Training and Evaluating with {vectorizer_name} ---\")\n",
    "\n",
    "    # Fit and transform the training data\n",
    "    print(f\"Fitting {vectorizer_name}...\")\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    print(f\"Transforming validation data with {vectorizer_name}...\")\n",
    "    X_val_vec = vectorizer.transform(X_val)\n",
    "    print(f\"Feature shape (Train): {X_train_vec.shape}\")\n",
    "\n",
    "    # Train Logistic Regression model\n",
    "    print(\"Training Logistic Regression model...\")\n",
    "    # Increased max_iter for convergence, added random_state for reproducibility\n",
    "    model = LogisticRegression(max_iter=100, random_state=42, solver='liblinear')\n",
    "    model.fit(X_train_vec, y_train)\n",
    "    print(\"Model training complete.\")\n",
    "\n",
    "    # --- Evaluation ---\n",
    "    print(\"\\nEvaluating model...\")\n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train_vec)\n",
    "    y_val_pred = model.predict(X_val_vec)\n",
    "\n",
    "    # Accuracy\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"\\nOverall Accuracy ({vectorizer_name}):\")\n",
    "    print(f\"  Training Set: {train_accuracy:.4f}\")\n",
    "    print(f\"  Validation Set: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Classification Report (includes per-class metrics)\n",
    "    print(f\"\\nClassification Report - Training Set ({vectorizer_name}):\")\n",
    "    print(classification_report(y_train, y_train_pred, target_names=class_names, zero_division=0))\n",
    "\n",
    "    print(f\"\\nClassification Report - Validation Set ({vectorizer_name}):\")\n",
    "    labels = sorted(set(np.unique(y_val)) | set(np.unique(y_val_pred)))\n",
    "    val_names_subset = [class_names[i] for i in labels]\n",
    "    print(classification_report(y_val, y_val_pred, target_names=val_names_subset, zero_division=0))\n",
    "\n",
    "    return model, vectorizer # Return trained model and vectorizer if needed later\n",
    "\n",
    "# --- 4. Run for TF-IDF ---\n",
    "# Initialize TF-IDF Vectorizer (using default English stop words)\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_model, _ = train_and_evaluate(tfidf_vectorizer, \"TF-IDF Vectorizer\", X_train, y_train, X_val, y_val, class_names)\n",
    "\n",
    "# --- 5. Run for CountVectorizer ---\n",
    "# Initialize Count Vectorizer (using default English stop words)\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_model, _ = train_and_evaluate(count_vectorizer, \"Count Vectorizer\", X_train, y_train, X_val, y_val, class_names)\n",
    "\n",
    "print(\"\\n--- Part A Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training and Evaluating with TF-IDF Vectorizer ---\n",
      "Fitting TF-IDF Vectorizer...\n",
      "Transforming validation data with TF-IDF Vectorizer...\n",
      "Feature shape (Train): (19873, 66333)\n",
      "Training Logistic Regression model...\n",
      "Model training complete.\n",
      "\n",
      "Evaluating model...\n",
      "\n",
      "Overall Accuracy (TF-IDF Vectorizer):\n",
      "  Training Set: 0.8683\n",
      "  Validation Set: 0.5235\n",
      "\n",
      "Classification Report - Training Set (TF-IDF Vectorizer):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1TV       0.97      0.60      0.74       158\n",
      "       ALJAZ       1.00      0.91      0.95       230\n",
      "     BBCNEWS       0.74      0.97      0.84      1576\n",
      "   BELARUSTV       0.97      0.59      0.73       109\n",
      "   BLOOMBERG       0.93      0.95      0.94      1441\n",
      "        CNBC       0.88      0.90      0.89      1319\n",
      "        CNNW       0.85      0.97      0.91      2725\n",
      "         COM       1.00      0.17      0.30        40\n",
      "       CSPAN       0.74      0.85      0.79       913\n",
      "      CSPAN2       0.72      0.73      0.73       904\n",
      "      CSPAN3       0.73      0.69      0.71       664\n",
      "          DW       1.00      0.86      0.93       253\n",
      "         FBC       0.91      0.92      0.92      1608\n",
      "    FOXNEWSW       0.87      0.87      0.87      1106\n",
      "         GBN       0.91      0.91      0.91       717\n",
      "        KDTV       0.97      0.99      0.98       176\n",
      "         KGO       0.96      0.79      0.87       763\n",
      "        KNTV       0.92      0.86      0.89       842\n",
      "        KPIX       0.97      0.62      0.76       400\n",
      "        KQED       1.00      0.15      0.26       113\n",
      "        KRON       0.95      0.91      0.93       760\n",
      "        KSTS       1.00      0.93      0.96       142\n",
      "        KTVU       0.91      0.89      0.90       766\n",
      "      LINKTV       1.00      0.51      0.68        43\n",
      "      MSNBCW       0.88      0.83      0.86      1141\n",
      "         NTV       0.93      0.83      0.88       209\n",
      "     PRESSTV       0.97      0.88      0.92       115\n",
      "          RT       1.00      0.38      0.55        50\n",
      "     RUSSIA1       1.00      0.24      0.39       108\n",
      "    RUSSIA24       1.00      0.58      0.74       122\n",
      "       SFGTV       0.99      0.91      0.95       360\n",
      "\n",
      "    accuracy                           0.87     19873\n",
      "   macro avg       0.93      0.75      0.80     19873\n",
      "weighted avg       0.88      0.87      0.86     19873\n",
      "\n",
      "\n",
      "Classification Report - Validation Set (TF-IDF Vectorizer):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ALJAZ       1.00      0.24      0.39        29\n",
      "     BBCNEWS       0.50      0.75      0.60       271\n",
      "   BLOOMBERG       0.62      0.84      0.71       170\n",
      "        CNBC       0.64      0.70      0.67       256\n",
      "        CNNW       0.38      0.76      0.51       219\n",
      "       CSPAN       0.45      0.47      0.46       204\n",
      "      CSPAN2       0.26      0.41      0.32       165\n",
      "      CSPAN3       0.30      0.04      0.07       177\n",
      "          DW       0.33      0.02      0.04        46\n",
      "         FBC       0.70      0.68      0.69       214\n",
      "    FOXNEWSW       0.63      0.50      0.56       250\n",
      "         GBN       0.21      0.86      0.34        14\n",
      "        KDTV       0.74      0.78      0.76        32\n",
      "         KGO       0.61      0.31      0.41       141\n",
      "        KNTV       0.53      0.34      0.41       185\n",
      "        KPIX       0.71      0.20      0.32        59\n",
      "        KQED       1.00      0.06      0.11        18\n",
      "        KRON       0.63      0.50      0.56       151\n",
      "        KSTS       0.76      0.86      0.81        22\n",
      "        KTVU       0.49      0.50      0.50       115\n",
      "      MSNBCW       0.66      0.60      0.63       223\n",
      "     PRESSTV       0.00      0.00      0.00         0\n",
      "          RT       0.00      0.00      0.00        41\n",
      "       SFGTV       0.89      0.22      0.35        37\n",
      "\n",
      "    accuracy                           0.52      3039\n",
      "   macro avg       0.54      0.44      0.42      3039\n",
      "weighted avg       0.54      0.52      0.50      3039\n",
      "\n",
      "\n",
      "--- Training and Evaluating with Count Vectorizer ---\n",
      "Fitting Count Vectorizer...\n",
      "Transforming validation data with Count Vectorizer...\n",
      "Feature shape (Train): (19873, 66333)\n",
      "Training Logistic Regression model...\n",
      "Model training complete.\n",
      "\n",
      "Evaluating model...\n",
      "\n",
      "Overall Accuracy (Count Vectorizer):\n",
      "  Training Set: 0.9859\n",
      "  Validation Set: 0.5130\n",
      "\n",
      "Classification Report - Training Set (Count Vectorizer):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1TV       1.00      1.00      1.00       158\n",
      "       ALJAZ       1.00      1.00      1.00       230\n",
      "     BBCNEWS       0.99      1.00      1.00      1576\n",
      "   BELARUSTV       1.00      1.00      1.00       109\n",
      "   BLOOMBERG       1.00      1.00      1.00      1441\n",
      "        CNBC       1.00      1.00      1.00      1319\n",
      "        CNNW       1.00      1.00      1.00      2725\n",
      "         COM       1.00      1.00      1.00        40\n",
      "       CSPAN       0.95      0.92      0.93       913\n",
      "      CSPAN2       0.91      0.87      0.89       904\n",
      "      CSPAN3       0.80      0.90      0.85       664\n",
      "          DW       1.00      1.00      1.00       253\n",
      "         FBC       1.00      1.00      1.00      1608\n",
      "    FOXNEWSW       1.00      1.00      1.00      1106\n",
      "         GBN       1.00      1.00      1.00       717\n",
      "        KDTV       1.00      1.00      1.00       176\n",
      "         KGO       1.00      1.00      1.00       763\n",
      "        KNTV       1.00      1.00      1.00       842\n",
      "        KPIX       1.00      1.00      1.00       400\n",
      "        KQED       1.00      1.00      1.00       113\n",
      "        KRON       1.00      1.00      1.00       760\n",
      "        KSTS       1.00      1.00      1.00       142\n",
      "        KTVU       1.00      1.00      1.00       766\n",
      "      LINKTV       1.00      1.00      1.00        43\n",
      "      MSNBCW       1.00      1.00      1.00      1141\n",
      "         NTV       1.00      1.00      1.00       209\n",
      "     PRESSTV       1.00      1.00      1.00       115\n",
      "          RT       1.00      1.00      1.00        50\n",
      "     RUSSIA1       1.00      0.99      1.00       108\n",
      "    RUSSIA24       1.00      1.00      1.00       122\n",
      "       SFGTV       1.00      1.00      1.00       360\n",
      "\n",
      "    accuracy                           0.99     19873\n",
      "   macro avg       0.99      0.99      0.99     19873\n",
      "weighted avg       0.99      0.99      0.99     19873\n",
      "\n",
      "\n",
      "Classification Report - Validation Set (Count Vectorizer):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1TV       0.00      0.00      0.00         0\n",
      "       ALJAZ       0.79      0.38      0.51        29\n",
      "     BBCNEWS       0.64      0.62      0.63       271\n",
      "   BLOOMBERG       0.65      0.81      0.72       170\n",
      "        CNBC       0.58      0.70      0.63       256\n",
      "        CNNW       0.43      0.58      0.49       219\n",
      "       CSPAN       0.42      0.50      0.46       204\n",
      "      CSPAN2       0.24      0.37      0.29       165\n",
      "      CSPAN3       0.26      0.08      0.12       177\n",
      "          DW       0.74      0.30      0.43        46\n",
      "         FBC       0.62      0.67      0.65       214\n",
      "    FOXNEWSW       0.56      0.48      0.51       250\n",
      "         GBN       0.24      0.79      0.37        14\n",
      "        KDTV       0.71      0.75      0.73        32\n",
      "         KGO       0.52      0.40      0.45       141\n",
      "        KNTV       0.38      0.38      0.38       185\n",
      "        KPIX       0.58      0.32      0.41        59\n",
      "        KQED       1.00      0.06      0.11        18\n",
      "        KRON       0.63      0.50      0.56       151\n",
      "        KSTS       0.70      0.86      0.78        22\n",
      "        KTVU       0.43      0.50      0.47       115\n",
      "      MSNBCW       0.60      0.62      0.61       223\n",
      "     PRESSTV       0.00      0.00      0.00         0\n",
      "          RT       0.00      0.00      0.00        41\n",
      "    RUSSIA24       0.00      0.00      0.00         0\n",
      "       SFGTV       0.85      0.30      0.44        37\n",
      "\n",
      "    accuracy                           0.51      3039\n",
      "   macro avg       0.48      0.42      0.41      3039\n",
      "weighted avg       0.52      0.51      0.50      3039\n",
      "\n",
      "\n",
      "--- Part A Complete ---\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate(vectorizer, vectorizer_name, X_train, y_train, X_val, y_val, class_names):\n",
    "    \"\"\"\n",
    "    Trains a Logistic Regression model using the specified vectorizer\n",
    "    and evaluates its performance.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Training and Evaluating with {vectorizer_name} ---\")\n",
    "\n",
    "    # Fit and transform the training data\n",
    "    print(f\"Fitting {vectorizer_name}...\")\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    print(f\"Transforming validation data with {vectorizer_name}...\")\n",
    "    X_val_vec = vectorizer.transform(X_val)\n",
    "    print(f\"Feature shape (Train): {X_train_vec.shape}\")\n",
    "\n",
    "    # Train Logistic Regression model\n",
    "    print(\"Training Logistic Regression model...\")\n",
    "    # Increased max_iter for convergence, added random_state for reproducibility\n",
    "    model = LogisticRegression(max_iter=100, random_state=42, solver='newton-cg')\n",
    "    model.fit(X_train_vec, y_train)\n",
    "    print(\"Model training complete.\")\n",
    "\n",
    "    # --- Evaluation ---\n",
    "    print(\"\\nEvaluating model...\")\n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train_vec)\n",
    "    y_val_pred = model.predict(X_val_vec)\n",
    "\n",
    "    # Accuracy\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    print(f\"\\nOverall Accuracy ({vectorizer_name}):\")\n",
    "    print(f\"  Training Set: {train_accuracy:.4f}\")\n",
    "    print(f\"  Validation Set: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Classification Report (includes per-class metrics)\n",
    "    print(f\"\\nClassification Report - Training Set ({vectorizer_name}):\")\n",
    "    print(classification_report(y_train, y_train_pred, target_names=class_names, zero_division=0))\n",
    "\n",
    "    print(f\"\\nClassification Report - Validation Set ({vectorizer_name}):\")\n",
    "    labels = sorted(set(np.unique(y_val)) | set(np.unique(y_val_pred)))\n",
    "    val_names_subset = [class_names[i] for i in labels]\n",
    "    print(classification_report(y_val, y_val_pred, target_names=val_names_subset, zero_division=0))\n",
    "\n",
    "    return model, vectorizer # Return trained model and vectorizer if needed later\n",
    "\n",
    "# --- 4. Run for TF-IDF ---\n",
    "# Initialize TF-IDF Vectorizer (using default English stop words)\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_model, _ = train_and_evaluate(tfidf_vectorizer, \"TF-IDF Vectorizer\", X_train, y_train, X_val, y_val, class_names)\n",
    "\n",
    "# --- 5. Run for CountVectorizer ---\n",
    "# Initialize Count Vectorizer (using default English stop words)\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_model, _ = train_and_evaluate(count_vectorizer, \"Count Vectorizer\", X_train, y_train, X_val, y_val, class_names)\n",
    "\n",
    "print(\"\\n--- Part A Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForSequenceClassification\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrainingArguments, Trainer, DataCollatorWithPadding\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, DatasetDict, load_metric\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "# ---------------------- 1. Imports & basic setup ----------------------\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "from datasets import Dataset, DatasetDict, load_metric\n",
    "\n",
    "# ---------------------- 2. Load your DataFrame -----------------------\n",
    "# (If train_df already lives in memory, skip this read step.)\n",
    "# train_df = pd.read_csv(\"your_dataframe.csv\")\n",
    "\n",
    "texts   = train_df[\"cleaned_text\"].astype(str).tolist()\n",
    "labels  = train_df[\"channel\"].tolist()\n",
    "\n",
    "# Encode string labels → integer IDs 0-30\n",
    "le           = LabelEncoder()\n",
    "int_labels   = le.fit_transform(labels)          # shape (N,)\n",
    "\n",
    "# Optional: keep a mapping of id↔label for inference\n",
    "id2label = {i: l for i, l in enumerate(le.classes_)}\n",
    "label2id = {l: i for i, l in id2label.items()}\n",
    "\n",
    "# ---------------------- 3. Train/validation split --------------------\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, int_labels, test_size=0.1, random_state=42, stratify=int_labels\n",
    ")\n",
    "\n",
    "# Wrap in 🤗 datasets Dataset objects\n",
    "train_ds = Dataset.from_dict({\"text\": train_texts, \"label\": train_labels})\n",
    "val_ds   = Dataset.from_dict({\"text\": val_texts,   \"label\": val_labels})\n",
    "\n",
    "dataset = DatasetDict({\"train\": train_ds, \"validation\": val_ds})\n",
    "\n",
    "# ---------------------- 4. Tokenisation function ---------------------\n",
    "MODEL_NAME = \"distilbert-base-uncased\"           # lightweight; swap for another model if desired\n",
    "tokenizer  = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True)\n",
    "\n",
    "dataset = dataset.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "# ---------------------- 5. Model & training prep ---------------------\n",
    "num_labels = len(le.classes_)                    # =31\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "accuracy = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(-1)\n",
    "    return accuracy.compute(predictions=preds, references=labels)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"news-channel-clf\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"               # disable W&B/Comet if not needed\n",
    ")\n",
    "\n",
    "# ---------------------- 6. Trainer -------------------------------\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# ---------------------- 7. Train! -------------------------------\n",
    "trainer.train()\n",
    "\n",
    "# ---------------------- 8. Quick evaluation ----------------------\n",
    "print(trainer.evaluate())\n",
    "\n",
    "# ---------------------- 9. Saving -------------------------------\n",
    "trainer.save_model(\"news-channel-clf/best_model\")\n",
    "tokenizer.save_pretrained(\"news-channel-clf/best_model\")\n",
    "\n",
    "# To reload later:\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"news-channel-clf/best_model\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"news-channel-clf/best_model\")\n",
    "\n",
    "# ---------------------- 10. Inference helper ---------------------\n",
    "def predict_channel(raw_text: str) -> str:\n",
    "    inputs   = tokenizer(raw_text, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "    logits   = model(**inputs).logits\n",
    "    pred_id  = logits.argmax(-1).item()\n",
    "    return id2label[pred_id]\n",
    "\n",
    "# Example:\n",
    "# print(predict_channel(\"Breaking: central bank raises interest rates again...\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/cs-181-final/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs-181-final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
